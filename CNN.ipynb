{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d50db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 25s 24ms/step - loss: 0.1898 - accuracy: 0.9418\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.0495 - accuracy: 0.9845\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.0352 - accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 0.0270 - accuracy: 0.9910\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0219 - accuracy: 0.9927\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0181 - accuracy: 0.9937\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0146 - accuracy: 0.9951\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0135 - accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0117 - accuracy: 0.9957\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0378 - accuracy: 0.9906\n",
      "Test Loss: 0.037763990461826324\n",
      "Test Accuracy: 0.9905999898910522\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1dd82f",
   "metadata": {},
   "source": [
    "TensorFlow: A machine learning framework for creating and training neural networks.\n",
    "Keras: A high-level API for building neural networks, now part of TensorFlow.\n",
    "MNIST: A dataset of handwritten digits widely used for training and evaluating machine learning models.\n",
    "Sequential Model: A simple linear stack of layers, ideal for straightforward model architectures.\n",
    "Conv2D, MaxPooling2D, Flatten, Dense: Layers commonly used in CNNs.\n",
    "to_categorical: A utility function to convert class labels to one-hot encoded format.\n",
    "    \n",
    "Loading Data: The mnist.load_data() function loads the MNIST dataset, returning training and test sets.\n",
    "Reshaping and Normalizing: The code reshapes the images to have a single channel (grayscale) and scales pixel values to the range [0, 1] by dividing by 255. This normalization step improves convergence during training.\n",
    "One-Hot Encoding: Converts the labels (digits 0-9) into a one-hot encoded format, where each label is represented as a binary vector (e.g., 3 becomes [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]).\n",
    "    \n",
    "Sequential Model: Defines a straightforward CNN with a stack of layers.\n",
    "Conv2D Layers: Perform 2D convolutions on the input images. Convolutional layers apply filters (small matrices) to detect features such as edges or textures.\n",
    "Activation Function: ReLU (Rectified Linear Unit) is used in the convolutional layers, introducing non-linearity to the model.\n",
    "MaxPooling2D: Reduces the spatial dimensions of the feature maps, typically by taking the maximum value in each pooling region. This process helps reduce computational complexity and captures significant features.\n",
    "Flatten: Converts the 3D feature maps into a 1D vector for input into dense (fully connected) layers.\n",
    "Dense Layers: Fully connected layers where each node is connected to every node in the previous layer. The final dense layer uses the softmax activation function, producing a probability distribution across 10 classes, corresponding to digits 0-9.\n",
    "    \n",
    "Optimizer: Adam (Adaptive Moment Estimation) is a commonly used optimizer for deep learning. It combines the benefits of adaptive learning rates and momentum.\n",
    "Loss Function: Categorical cross-entropy is used for multi-class classification tasks with one-hot encoded labels.\n",
    "Metrics: Accuracy is used to evaluate model performance during training and testing.\n",
    "    \n",
    "Training: The fit method trains the model on the training data.\n",
    "Batch Size: 64 images are processed at a time during each training step (minibatch training).\n",
    "Epochs: The model is trained for 10 epochs, indicating how many times the entire training set is passed through the network.\n",
    "Verbose: Specifies the level of detail for logging during training.\n",
    "    \n",
    "Evaluation: The evaluate method computes the loss and accuracy on the test set, providing a measure of the model's performance on unseen data.\n",
    "Loss: Indicates how well the model fits the test data. Lower loss generally means better performance.\n",
    "Accuracy: The proportion of correct predictions out of the total predictions, used to assess classification performance.\n",
    "\n",
    "Conclusion\n",
    "This code snippet demonstrates how to build, train, and evaluate a CNN for digit classification using the MNIST dataset. The model structure, activation functions, optimizer, and loss function are common choices for this type of task. The code's modularity and flexibility make it a solid starting point for more complex deep learning projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4026e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
